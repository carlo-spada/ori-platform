# Task 1.1: Infrastructure Audit (Stripe, Resend, PostgreSQL)

**Task ID**: mcp-integration/1.1
**Epic**: MCP Integration Phase 1
**Owner**: Claude
**Status**: READY TO START
**Effort**: ~16 hours
**Timeline**: Week 1 (Tue-Wed)

## Objective

Conduct comprehensive audits of the three systems that will be integrated with MCP servers. The goal is to understand:

- Current implementation status and architecture
- All files and dependencies involved
- Testing patterns and gaps
- Integration points where MCP will be added
- Risks and blockers

## Deliverables

Three audit documents:

1. `docs/STRIPE_MCP_READINESS.md` (2-3 pages)
2. `docs/RESEND_MCP_READINESS.md` (2-3 pages)
3. `docs/POSTGRES_MCP_READINESS.md` (2-3 pages)

Each document should contain:

- Current implementation status
- File inventory and dependencies
- Testing patterns and coverage
- Integration points for MCP
- Blockers and risks
- Readiness assessment

## Audit: Stripe (Payment System)

### Files to Audit

```
services/core-api/
├── src/
│   ├── lib/stripe.ts              (Stripe client initialization)
│   ├── lib/stripeHelpers.ts       (Helper functions)
│   ├── routes/payments.ts          (Payment endpoints)
│   ├── routes/subscriptions.ts     (Subscription endpoints)
│   ├── routes/setupIntent.ts       (Setup intent endpoint)
│   ├── routes/__tests__/
│   │   └── payments.test.ts        (Payment tests)
│   └── scripts/
│       └── setupStripe.ts          (Stripe setup script)
│
src/
├── lib/stripe.ts                   (Frontend Stripe config)
├── integrations/api/payments.ts    (API client)
└── hooks/usePayments.ts            (React hooks)
```

### Questions to Answer

1. **Current Implementation**
   - What Stripe features are currently implemented? (customers, subscriptions, invoices, webhooks)
   - How many webhook types are handled? List them.
   - What's the current test coverage for payment flows?
   - Are there any manual testing procedures documented?

2. **Integration Points**
   - Where in the code do manual Stripe API calls happen?
   - What test data is currently generated manually?
   - How are webhooks currently simulated?
   - What Stripe environments are used? (sandbox, production, test)

3. **Testing**
   - How many test files involve Stripe? What's their coverage?
   - Are tests currently mocking Stripe or using real API?
   - What payment scenarios are tested? What's missing?
   - How are webhook scenarios tested?

4. **Risks & Gaps**
   - Are there any payment flows without tests?
   - Are there any edge cases not covered?
   - What would break if manual Stripe dashboard testing was removed?

5. **Readiness for MCP**
   - All Stripe-related code identified? Yes/No
   - Clear testing patterns? Yes/No
   - Ready to add MCP helpers? Yes/No
   - Any blockers? List them.

### Acceptance Criteria

- [ ] All Stripe-related files identified and documented
- [ ] Current test coverage assessed and documented
- [ ] 5 webhook types documented
- [ ] Current manual testing procedures identified
- [ ] At least 3 integration points identified where MCP will be added
- [ ] Readiness assessment: GREEN (no blockers)

---

## Audit: Resend (Email System)

### Files to Audit

```
services/core-api/
├── src/
│   ├── utils/notifications.ts      (Placeholder email utilities)
│   ├── routes/users.ts             (User signup - potential email trigger)
│   └── routes/applications.ts      (Application tracking - potential email trigger)
│
src/
├── hooks/useProfile.ts             (User profile updates)
├── components/profile/              (Profile-related components)
└── app/app/                        (Authenticated app routes with email potential)
```

### Questions to Answer

1. **Current Implementation**
   - What's the current state of `notifications.ts`? (placeholder? partial? non-functional?)
   - What email providers are integrated? (none currently?)
   - Where should email be triggered? (signup, recommendations, alerts, receipts)
   - What email templates exist? (any? where?)

2. **User Journeys**
   - What user actions should trigger emails?
     - Signup → Welcome email?
     - Job recommendation → Notification email?
     - Application status change → Alert email?
     - Payment → Receipt email?
   - Which are currently implemented?
   - Which are missing?

3. **Integration Points**
   - Where in signup flow should welcome email be sent?
   - Where in recommendation flow should notification email be sent?
   - Where should alert emails be sent?
   - What data needs to be passed to email templates?

4. **Testing**
   - How is email currently tested? (not at all?)
   - What test infrastructure exists for email?
   - How should email be tested with Resend MCP?

5. **Risks & Gaps**
   - Is email critical for user experience?
   - What would break without email?
   - Are there any compliance/legal concerns? (GDPR, CAN-SPAM)
   - Are there unsubscribe/preference requirements?

6. **Readiness for MCP**
   - Email system architected? Yes/No (likely No - placeholder)
   - Integration points identified? Yes/No
   - Ready to implement EmailService? Yes/No
   - Any blockers? List them.

### Acceptance Criteria

- [ ] `notifications.ts` status assessed
- [ ] At least 4 user journeys identified that need email
- [ ] Current email triggers documented (likely none)
- [ ] All integration points identified
- [ ] Email compliance requirements documented
- [ ] Readiness assessment: GREEN (email system is greenfield)

---

## Audit: PostgreSQL (Database System)

### Files to Audit

```
supabase/
├── migrations/                     (Database migration files)
└── config.toml                     (Supabase config)

services/core-api/src/
├── __tests__/
│   ├── setup.ts                    (Database test setup)
│   └── *.test.ts                   (Database-related tests)
├── lib/supabase.ts                 (Supabase client)
├── routes/__tests__/               (Integration tests using DB)
│   ├── profile.test.ts
│   ├── applications.test.ts
│   ├── skills-gap.test.ts
│   └── ...

docs/
├── DATABASE_SCHEMA.md              (Schema documentation)
└── API_ENDPOINTS.md                (Endpoint documentation)
```

### Questions to Answer

1. **Current Implementation**
   - How many tables in the database? List them.
   - What's the schema for core tables? (user_profiles, experiences, applications, education)
   - How many RLS policies exist? List them.
   - How many migrations have been applied?

2. **Testing Patterns**
   - How is database testing currently done? (Jest, Supabase client)
   - What test data setup exists? (fixtures, factories, seeds)
   - How are RLS policies tested?
   - How are migrations tested?
   - What's the current test coverage for database operations?

3. **RLS Policies**
   - How many RLS policies are active?
   - What's the pattern? (auth.uid() = user_id?)
   - How are they tested?
   - Are there gaps in RLS coverage?

4. **Migrations**
   - How many migrations exist?
   - What's the current approach to testing migrations?
   - How are rollbacks tested?
   - What validation exists for migrations?

5. **Developer Workflows**
   - How do developers currently explore schema? (psql, DBeaver)
   - How do they test RLS policies? (manual SQL)
   - How do they validate migrations? (apply and test)
   - How much context-switching is involved?

6. **Readiness for MCP**
   - All database files documented? Yes/No
   - Clear testing patterns? Yes/No
   - RLS policies well-documented? Yes/No
   - Ready to add PostgreSQL MCP helpers? Yes/No
   - Any blockers? List them.

### Acceptance Criteria

- [ ] All database files identified and documented
- [ ] Core tables documented (schemas, RLS policies)
- [ ] At least 5 RLS policies identified
- [ ] Current testing patterns documented
- [ ] Current developer workflows documented
- [ ] At least 3 integration points identified for PostgreSQL MCP
- [ ] Readiness assessment: GREEN (no blockers)

---

## How to Conduct Audit

1. **File Discovery**
   - Use `Glob` tool to find all relevant files
   - Document complete file paths
   - Note dependencies and imports

2. **Code Review**
   - Read each file and understand its purpose
   - Note integration points
   - Identify testing gaps
   - Look for manual/redundant procedures

3. **Testing Analysis**
   - Review test files in `__tests__/` directories
   - Assess coverage
   - Identify untested scenarios
   - Note manual testing procedures

4. **Documentation**
   - Create audit document for each system
   - Include findings and analysis
   - Provide readiness assessment
   - Identify blockers

## Submission Format

Each audit document should follow this structure:

```markdown
# [System] MCP Readiness Assessment

## Current Status

Brief paragraph on current implementation state

## File Inventory

- Core files: (list)
- Test files: (list)
- Configuration: (list)

## Implementation Analysis

- [Specific findings for this system]

## Testing Assessment

- Current coverage: X%
- Gaps: [list]
- Recommended improvements: [list]

## Integration Points for MCP

1. [Point 1]
2. [Point 2]
3. [Point 3]

## Risks & Blockers

- [Risk/blocker 1]
- [Risk/blocker 2]

## Readiness Assessment

- **Overall**: GREEN / YELLOW / RED
- **Recommendation**: Ready for Phase 2 / Needs adjustments

## Next Steps for MCP Integration

1. [Action 1]
2. [Action 2]
```

## Success Definition

✅ Task is complete when:

1. All three audit documents created and thorough
2. All files involved identified and documented
3. Testing patterns and gaps documented
4. Integration points clearly identified
5. No surprises for Phase 1.2 (MCP setup)
6. Team consensus on findings

## References

- Master Plan: `docs/MCP_INTEGRATION_MASTER_PLAN.md` (Section: Phase 1.1)
- Architecture: `docs/MCP_PHASE1_ARCHITECTURE.md`
- Current implementation: CLAUDE.md (Architecture & Data Flow sections)

## Notes

- This is purely discovery - no code changes yet
- Document findings as you go
- Ask questions if anything is unclear
- Flag any surprises for team discussion
- Estimated 4-5 hours per system audit

---

**Task Created**: November 2025
**Ready to Start**: Week 1, Tuesday
**Due**: Week 1, Friday
